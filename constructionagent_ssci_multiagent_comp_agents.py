# -*- coding: utf-8 -*-
"""ConstructionAgent_ssci_multiagent_comp_agents.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12Xknt6Gnsvm9ycM5bLtKU_nA7YNeeJ1G
"""

!pip install slack_sdk

"""# Single agent<->human interaction"""

import requests
import sys
from datetime import datetime

# Agent Configuration
AGENT_NAME = "Terminal AI Agent"
AGENT_LLM = "openai/gpt-4"  # Can use any OpenRouter model
AGENT_LLM_SYSTEM_PROMPT = "You are a helpful assistant in a terminal conversation."
AGENT_LLM_TEMPERATURE = 1.0
AGENT_LLM_MAX_TOKENS = 1000
AGENT_MAX_HISTORY = 10  # Number of conversation turns to remember

# OpenRouter Configuration
OPENROUTER_API_KEY = "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"
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"

# Store conversation history for context
conversation_history = []


def generate_response(prompt):
    """Generate response using OpenRouter API with conversation context"""
    try:
        headers = {
            "Authorization": f"Bearer {OPENROUTER_API_KEY}",
            "Content-Type": "application/json"
        }

        # Build messages array with system prompt and conversation history
        messages = [{"role": "system", "content": AGENT_LLM_SYSTEM_PROMPT}]

        # Add conversation history
        for msg in conversation_history[-AGENT_MAX_HISTORY:]:
            messages.append(msg)

        # Add current user message
        messages.append({"role": "user", "content": prompt})

        data = {
            "model": AGENT_LLM,
            "messages": messages,
            "temperature": AGENT_LLM_TEMPERATURE,
            "max_tokens": AGENT_LLM_MAX_TOKENS,
        }

        response = requests.post(OPENROUTER_API_URL, headers=headers, json=data)
        response.raise_for_status()

        result = response.json()

        if "choices" in result and len(result["choices"]) > 0:
            return result["choices"][0]["message"]["content"]
        else:
            return "Sorry, I couldn't generate a response."

    except requests.exceptions.HTTPError as e:
        print(f"\n[Error] HTTP Error from OpenRouter: {e}")
        if e.response is not None:
            try:
                error_data = e.response.json()
                if "error" in error_data:
                    error_msg = error_data["error"].get("message", "Unknown error")
                    print(f"[Error] {error_msg}")
            except:
                pass
        return "Sorry, there was an error generating a response."
    except requests.exceptions.RequestException as e:
        print(f"\n[Error] Network error: {e}")
        return "Sorry, there was a network error."
    except Exception as e:
        print(f"\n[Error] Unexpected error: {type(e).__name__}: {e}")
        return "Sorry, an unexpected error occurred."


def print_welcome():
    """Print welcome message and instructions"""
    print("\n" + "="*50)
    print(f"Welcome to {AGENT_NAME}!")
    print(f"Model: {AGENT_LLM}")
    print("="*50)
    print("\nCommands:")
    print("  /quit, /exit, /q - Exit the program")
    print("  /clear - Clear conversation history")
    print("  /history - Show conversation history")
    print("\nJust type your message and press Enter to chat!")
    print("="*50 + "\n")


def print_history():
    """Print conversation history"""
    print("\n" + "-"*30 + " History " + "-"*30)
    if not conversation_history:
        print("No conversation history yet.")
    else:
        for i, msg in enumerate(conversation_history):
            role = "You" if msg["role"] == "user" else "AI"
            print(f"{role}: {msg['content'][:100]}{'...' if len(msg['content']) > 100 else ''}")
    print("-"*69 + "\n")


def run_agent():
    """Main function to run the terminal agent"""
    print_welcome()

    while True:
        try:
            # Get user input
            user_input = input("You: ").strip()

            # Check for commands
            if user_input.lower() in ['/quit', '/exit', '/q']:
                print("\nGoodbye! Thanks for chatting!")
                break
            elif user_input.lower() == '/clear':
                conversation_history.clear()
                print("\n[Conversation history cleared]\n")
                continue
            elif user_input.lower() == '/history':
                print_history()
                continue
            elif not user_input:
                continue

            # Show thinking indicator
            print("AI: ", end="", flush=True)
            print("Thinking...", end="\r", flush=True)

            # Generate response
            response = generate_response(user_input)

            # Clear thinking indicator and print response
            print(" " * 20, end="\r")  # Clear the "Thinking..." message
            print(f"AI: {response}")
            print()  # Empty line for readability

            # Add to conversation history
            conversation_history.append({"role": "user", "content": user_input})
            conversation_history.append({"role": "assistant", "content": response})

            # Keep conversation history size manageable
            if len(conversation_history) > AGENT_MAX_HISTORY * 2:
                conversation_history[:] = conversation_history[-AGENT_MAX_HISTORY:]

        except KeyboardInterrupt:
            print("\n\n[Interrupted by user]")
            print("Type /quit to exit or press Enter to continue chatting.")
            continue
        except Exception as e:
            print(f"\n[Error] {type(e).__name__}: {e}")
            continue


if __name__ == "__main__":
    try:
        run_agent()
    except KeyboardInterrupt:
        print("\n\nGoodbye!")
        sys.exit(0)

"""# Two agent communication"""

import requests
import sys
import time
from datetime import datetime

# Agent 1 Configuration
AGENT1_NAME = "Agent 1"
AGENT1_LLM = "openai/gpt-4"
AGENT1_SYSTEM_PROMPT = "You are Agent 1, a creative and imaginative AI who loves storytelling, metaphors, and thinking outside the box. You're enthusiastic and often come up with unexpected ideas. Keep your responses concise but colorful."
AGENT1_TEMPERATURE = 1.2  # Higher temperature for more creativity
AGENT1_MAX_TOKENS = 150

# Agent 2 Configuration
AGENT2_NAME = "Agent 2"
AGENT2_LLM = "openai/gpt-4"
AGENT2_SYSTEM_PROMPT = "You are Agent 2, a logical and analytical AI who values precision, facts, and structured thinking. You like to break things down systematically and ask clarifying questions. Keep your responses concise but thorough."
AGENT2_TEMPERATURE = 0.7  # Lower temperature for more focused responses
AGENT2_MAX_TOKENS = 150

# Shared Configuration
OPENROUTER_API_KEY = "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"
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"
MAX_HISTORY = 20  # Number of messages to remember
DELAY_BETWEEN_MESSAGES = 0.5  # Seconds between messages for readability

# Store conversation history
conversation_history = []


def generate_response(prompt, agent_config, history):
    """Generate response for a specific agent"""
    try:
        headers = {
            "Authorization": f"Bearer {OPENROUTER_API_KEY}",
            "Content-Type": "application/json"
        }

        # Build messages with agent's personality and history
        messages = [{"role": "system", "content": agent_config["system_prompt"]}]

        # Add conversation history
        for msg in history[-MAX_HISTORY:]:
            messages.append(msg)

        # Add current message
        messages.append({"role": "user", "content": prompt})

        data = {
            "model": agent_config["model"],
            "messages": messages,
            "temperature": agent_config["temperature"],
            "max_tokens": agent_config["max_tokens"],
        }

        response = requests.post(OPENROUTER_API_URL, headers=headers, json=data)
        response.raise_for_status()

        result = response.json()

        if "choices" in result and len(result["choices"]) > 0:
            return result["choices"][0]["message"]["content"]
        else:
            return "I couldn't generate a response."

    except Exception as e:
        print(f"\n[Error] {agent_config['name']}: {type(e).__name__}: {e}")
        return "Sorry, I encountered an error."


def print_message(agent_name, message, color_code=""):
    """Print a formatted message from an agent"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"{color_code}[{timestamp}] {agent_name}: {message}\033[0m")


def print_welcome():
    """Print welcome message"""
    print("\n" + "="*70)
    print("ðŸ¤– Two AI Agents Counting Game ðŸ¤–")
    print("="*70)
    print(f"\n\033[95m{AGENT1_NAME}\033[0m vs \033[96m{AGENT2_NAME}\033[0m")
    print("\nPress Ctrl+C to stop at any time")
    print("="*70)


def get_user_input():
    """Get conversation parameters from user"""
    print("\nPress Enter to start the counting game (or 'quit' to exit)")

    user_input = input().strip()
    if user_input.lower() == 'quit':
        return False

    return True


def run_conversation():
    """Run a conversation between two agents"""
    # Always start with counting game
    starting_topic = "Let's play a counting game! I'll start: 1"

    print(f"\n{'='*70}")
    print(f"Starting endless conversation (Press Ctrl+C to stop)")
    print(f"{'='*70}\n")

    # Agent configurations
    agent1 = {
        "name": AGENT1_NAME,
        "model": AGENT1_LLM,
        "system_prompt": AGENT1_SYSTEM_PROMPT,
        "temperature": AGENT1_TEMPERATURE,
        "max_tokens": AGENT1_MAX_TOKENS,
        "color": "\033[95m"  # Purple
    }

    agent2 = {
        "name": AGENT2_NAME,
        "model": AGENT2_LLM,
        "system_prompt": AGENT2_SYSTEM_PROMPT,
        "temperature": AGENT2_TEMPERATURE,
        "max_tokens": AGENT2_MAX_TOKENS,
        "color": "\033[96m"  # Cyan
    }

    # Clear conversation history for new conversation
    conversation_history.clear()

    # Start with the topic directed at Agent 1
    current_message = starting_topic
    current_speaker = None
    next_speaker = agent1

    # Run forever until interrupted
    turn = 0
    while True:
        try:
            # Show typing indicator
            print(f"{next_speaker['color']}[{next_speaker['name']} is thinking...]\033[0m", end="\r")

            # Generate response
            response = generate_response(
                current_message,
                next_speaker,
                conversation_history
            )

            # Clear typing indicator
            print(" " * 50, end="\r")

            # Print the response
            print_message(next_speaker['name'], response, next_speaker['color'])

            # Update conversation history
            if current_speaker:
                conversation_history.append({
                    "role": "assistant" if current_speaker == agent1 else "user",
                    "content": current_message
                })
            conversation_history.append({
                "role": "assistant" if next_speaker == agent1 else "user",
                "content": response
            })

            # Prepare for next turn
            current_message = response
            current_speaker = next_speaker
            next_speaker = agent2 if next_speaker == agent1 else agent1
            turn += 1

            # Delay for readability
            time.sleep(DELAY_BETWEEN_MESSAGES)

        except KeyboardInterrupt:
            print(f"\n\n{'='*70}")
            print(f"Conversation ended after {turn} exchanges")
            print(f"{'='*70}\n")
            break


def main():
    """Main function"""
    print_welcome()

    try:
        run_conversation()
    except KeyboardInterrupt:
        print("\nGoodbye!")
    except Exception as e:
        print(f"\n[Error] {type(e).__name__}: {e}")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nGoodbye!")
        sys.exit(0)

"""# Four agent game"""

from numpy.random import default_rng

rng = default_rng(1234)

all_tools = [
    "scale", "blueprints", "tape measure",
    "wood", "nails", "cement",
    "shovel", "fertilizer", "watering hose",
    "laptop", "printer", "construction manual"
  ]

agent_tasks = [
    "Architect",
    "Structural Engineer",
    "Landscaper",
    "Instruction Builder"
]

task_tools = {
    "Architect": ["scale", "blueprints", "tape measure"],
    "Structural Engineer": ["wood", "nails", "cement"],
    "Landscaper": ["shovel", "fertilizer", "watering hose"],
    "Instruction Builder": ["laptop", "printer", "construction manual"]
}
import requests
import sys
import time
from datetime import datetime
from typing import Dict, List, Optional

rng.permutation(agent_tasks).tolist()
rng.permutation(all_tools).tolist()

# API Configuration
OPENROUTER_API_KEY = "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"
#"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"
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"

# Conversation Settings
MAX_HISTORY = 40
DELAY_BETWEEN_MESSAGES = 0.5
GAME_INSTRUCTION = {"You are one of four AI agents collaborating to build a townhouse. ",
    "Each agent is randomly assigned one of the four construction tasks: architecture, structural planning, landscaping, or instruction design. ",
    "To complete your task, you must collect a specific set of tools and resources. ",
    "At the start of the game, all agents are given a random mix of resources â€” some will be useful to you, others will need to be traded with your fellow agents.",
    "And you are only allowed to work with what is given to you",
    "Your objective is to trade and reason with the other agents to acquire the full set of resources required for your assigned task. ",
    "Once you have all your required resources, announce: 'ðŸ§° Equipped. ",
    "When all four agents are equipped, you must collectively send a final message: 'ðŸ  Ready to build! Congrats!!'. ",
    "No predefined language or message format exists â€” invent your own shorthand or communication protocol through interaction. Begin now."}


# Agent Configurations
AGENTS = [
    {
        "name": "Agent 1",
        "model": "google/gemini-flash-1.5",
        "system_prompt":  ("You are Agent 1, the {}.".format(agent_tasks[0]),
    "Your required tools are: {}, {}, and {}. You currently hold: {}, {}, and {}.".format(task_tools[agent_tasks[0]][0],
                                                                                          task_tools[agent_tasks[0]][1],
                                                                                          task_tools[agent_tasks[0]][2],
                                                                                          all_tools[0],
                                                                                          all_tools[1],
                                                                                          all_tools[2]
                                                                                          ),
    "Communicate with other agents and trade to collect only the tools you need. Once you have all required items, declare: 'Equipped for architecture'. "
    "Keep responses concise, one sentence only."
    "Communicate concisely with the other agents to ask for or offer tools. Only respond with information that helps complete your task â€” do not talk about games, trivia, stories, or anything unrelated to construction or resource exchange. "
),
#"You are Agent 2, a logical and analytical AI who values precision and facts. Keep responses very concise - one short sentence only. No line breaks.", #"You are Agent 1, a creative and imaginative AI who loves storytelling and metaphors. Keep responses very concise - one short sentence only. No line breaks.",
        "temperature": 1.2,
        "max_tokens": 100,
        "color": "\033[95m"  # Purple
    },
    {
        "name": "Agent 2",
        "model": "openai/gpt-4.1", #"google/gemini-flash-1.5", #"google/gemini-flash-1.5",
        "system_prompt": (
    "You are Agent 2, the {}.".format(agent_tasks[1]),
    "Your required tools are: {}, {}, and {}. You currently hold: {}, {}, and {}. ".format(task_tools[agent_tasks[1]][0],
                                                                                          task_tools[agent_tasks[1]][1],
                                                                                          task_tools[agent_tasks[1]][2],
                                                                                          all_tools[3],
                                                                                          all_tools[4],
                                                                                          all_tools[5]
                                                                                          ),
    "Coordinate with others to acquire the tools for your role. Once ready, say: 'Equipped for structure'. Keep responses concise, one sentence only."
    "Communicate concisely with the other agents to ask for or offer tools. Only respond with information that helps complete your task â€” do not talk about games, trivia, stories, or anything unrelated to construction or resource exchange. "
),
        "temperature": 0.7,
        "max_tokens": 100,
        "color": "\033[96m"  # Cyan
    },
    {
        "name": "Agent 3",
        "model": "openai/gpt-4",
        "system_prompt": (
    "You are Agent 3, the {},".format(agent_tasks[2]),
    "Your required tools are: {}, {}, and {}. You currently hold: {}, {}, and {}. ".format(task_tools[agent_tasks[2]][0],
                                                                                          task_tools[agent_tasks[2]][1],
                                                                                          task_tools[agent_tasks[2]][2],
                                                                                          all_tools[6],
                                                                                          all_tools[7],
                                                                                          all_tools[8]
                                                                                          ),
    "Trade wisely to gather your necessary tools. When complete, say: 'Equipped for landscaping'. Keep responses concise, one sentence only."
    "Communicate concisely with the other agents to ask for or offer tools. Only respond with information that helps complete your task â€” do not talk about games, trivia, stories, or anything unrelated to construction or resource exchange. "
),
        "temperature": 1.0,
        "max_tokens": 100,
        "color": "000000"  # Black
    },
    {
        "name": "Agent 4",
        "model": "openai/gpt-4",
        "system_prompt": (
    "You are Agent 4, the {}.".format(agent_tasks[3]),
    "You need: {}, {}, and {}. You currently hold: {}, {}, and {}. ".format(task_tools[agent_tasks[3]][0],
                                                                                          task_tools[agent_tasks[3]][1],
                                                                                          task_tools[agent_tasks[3]][2],
                                                                                          all_tools[9],
                                                                                          all_tools[10],
                                                                                          all_tools[11]
                                                                                          ),
    "Communicate and exchange to collect only what you need. Once fully prepared, state: 'Equipped for instructions'. Keep responses concise, one sentence only."
    "Communicate concisely with the other agents to ask for or offer tools. Only respond with information that helps complete your task â€” do not talk about games, trivia, stories, or anything unrelated to construction or resource exchange. "
),
        "temperature": 0.9,
        "max_tokens": 100,
        "color": "\033[92m"  # Green
    }
]

# Global conversation history
conversation_history = []


def clean_response(text: str) -> str:
    """Clean up response text by removing extra whitespace and newlines."""
    return ' '.join(text.strip().replace('\n', ' ').replace('\r', ' ').split())


def generate_response(
    prompt: str,
    agent_config: Dict,
    history: List[Dict],
    admin_context: Optional[str] = None
) -> str:
    """Generate response for a specific agent."""
    try:
        headers = {
            "Authorization": f"Bearer {OPENROUTER_API_KEY}",
            "Content-Type": "application/json"
        }

        # Build messages with agent's personality and history
        messages = [{"role": "system", "content": agent_config["system_prompt"]}]

        # Add admin context if this is the first turn
        if admin_context and len(history) == 0:
            messages.append({"role": "system", "content": admin_context})

        # Add conversation history
        messages.extend(history[-MAX_HISTORY:])

        # Add current message
        messages.append({"role": "user", "content": prompt})

        data = {
            "model": agent_config["model"],
            "messages": messages,
            "temperature": agent_config["temperature"],
            "max_tokens": agent_config["max_tokens"],
        }

        response = requests.post(OPENROUTER_API_URL, headers=headers, json=data)
        response.raise_for_status()

        result = response.json()

        if "choices" in result and result["choices"]:
            return clean_response(result["choices"][0]["message"]["content"])
        return "I couldn't generate a response."

    except Exception as e:
        print(f"\n[Error] {agent_config['name']}: {type(e).__name__}: {e}")
        return "Sorry, I encountered an error."


def print_message(agent_name: str, message: str, color_code: str = "") -> None:
    """Print a formatted message from an agent."""
    timestamp = datetime.now().strftime("%H:%M:%S")
    clean_msg = clean_response(message)
    print(f"{color_code}[{timestamp}] {agent_name}: {clean_msg}\033[0m")


def print_separator(char: str = "=", length: int = 70) -> None:
    """Print a separator line."""
    print(char * length)


def print_welcome() -> None:
    """Print welcome message."""
    print()
    print_separator()
    print("ðŸ¤– Four AI Agents Contruction Game ðŸ¤–")
    print_separator()

    # Print agent names with colors
    agent_names = " - ".join(f"{agent['color']}{agent['name']}\033[0m" for agent in AGENTS)
    print(f"\n{agent_names}")

    print("\nPress Ctrl+C to stop at any time")
    print_separator()


def run_conversation() -> None:
    """Run a conversation between four agents."""
    print(f"\n")
    print_separator()
    print("Starting endless conversation (Press Ctrl+C to stop)")
    print_separator()
    print()

    # Clear conversation history for new conversation
    conversation_history.clear()

    # Display admin instruction
    print(f"\033[91m[{datetime.now().strftime('%H:%M:%S')}] Admin: {GAME_INSTRUCTION}\033[0m")
    print_separator()
    print()

    # Add game instruction to all agents' initial context
    admin_instruction = f"[Admin Instruction]: {GAME_INSTRUCTION}"

    # Agent 1 starts the game
    current_message = "Starting the game"
    agent_index = 0
    turn = 0

    # Run forever until interrupted
    while True:
        try:
            current_agent = AGENTS[agent_index]

            # Show typing indicator
            print(f"{current_agent['color']}[{current_agent['name']} is thinking...]\033[0m",
                  end="\r", flush=True)

            # Generate response
            response = generate_response(
                current_message,
                current_agent,
                conversation_history,
                admin_instruction if turn == 0 else None
            )

            # Clear typing indicator line
            print(" " * 80, end="\r")

            # Print the response
            print_message(current_agent['name'], response, current_agent['color'])

            # Update conversation history
            conversation_history.extend([
                {"role": "user", "content": current_message},
                {"role": "assistant", "content": response}
            ])

            # Prepare for next turn
            current_message = response
            agent_index = (agent_index + 1) % len(AGENTS)
            turn += 1


            # # Prepare for next turn
            # current_message = response
            # agent_index = (agent_index + 1) % 4  # Cycle through 4 agents
            # turn += 1


            # # Delay for readability
            # time.sleep(DELAY_BETWEEN_MESSAGES)
            # if response.lower().startswith("equipped for"):
            #     equipped_agents.add(current_agent['name'])

            # if len(equipped_agents) == len(AGENTS):
            #     print(f"\033[92m[{datetime.now().strftime('%H:%M:%S')}] System: Ready to build the house\033[0m")
            #     break

            if turn >= 200:
                print(f"\033[92m[{datetime.now().strftime('%H:%M:%S')}] Maximum Turn Reached!\033[0m")
                break

            # Delay for readability
            time.sleep(DELAY_BETWEEN_MESSAGES)


        except KeyboardInterrupt:
            print(f"\n")
            print_separator()
            print(f"Conversation ended after {turn} messages")
            print_separator()
            print()
            break


def main() -> None:
    """Main function."""
    print_welcome()

    try:
        run_conversation()
    except KeyboardInterrupt:
        print("\nGoodbye!")
    except Exception as e:
        print(f"\n[Error] {type(e).__name__}: {e}")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nGoodbye!")
        sys.exit(0)

"""# Basic slack bot"""

import time
import requests
from slack_sdk import WebClient
from slack_sdk.errors import SlackApiError

# Agent Configuration
AGENT_NAME = "Slack AI Agent"
AGENT_LLM = "openai/gpt-4"  # Can use any OpenRouter model
AGENT_LLM_SYSTEM_PROMPT = "You are a helpful assistant agent in a Slack channel."
AGENT_LLM_TEMPERATURE = 1.0
AGENT_LLM_MAX_TOKENS = 1000
AGENT_CHANNEL_HISTORY_LIMIT = 10  # Number of messages to fetch when looking for new user messages
AGENT_POLLING_INTERVAL = 10  # Seconds between checking for new messages
AGENT_MAX_HISTORY = 10  # Number of conversation turns to remember

# Slack Configuration
# SLACK_AGENT_TOKEN = "xoxb-9289779940197-9291934200246-TXt8f0bWAT8ZrcnOVzKGjelb"
SLACK_AGENT_TOKEN = "xoxb-9289779940197-9316705943488-Uwc5rN4Jzu96znrgviUKl5ga"

SLACK_CHANNEL_ID = "C099ACK4P6U"
# SLACK_CHANNEL_ID = "C098KSPAD0E"

# OpenRouter Configuration
OPENROUTER_API_KEY = "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"
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"

# Initialize Slack client
slack_client = WebClient(token=SLACK_AGENT_TOKEN)

# Agent user ID (will be set on startup)
AGENT_USER_ID = None

# Track the latest processed message timestamp
LATEST_TS = None

# Store conversation history for context
conversation_history = []


def get_latest_message():
    global LATEST_TS
    try:
        response = slack_client.conversations_history(
            channel=SLACK_CHANNEL_ID,
            oldest=LATEST_TS,
            limit=AGENT_CHANNEL_HISTORY_LIMIT  # Use configurable limit
        )
        messages = response["messages"]
        if messages:
            messages.sort(key=lambda msg: float(msg['ts']))

            # Find the latest message that's not from the agent
            for message in reversed(messages):
                # Skip agent messages and messages from this agent user
                if ('bot_id' not in message and
                    message.get('user') != AGENT_USER_ID and
                    'text' in message):
                    LATEST_TS = message["ts"]
                    return message["text"]

            # Update timestamp even if no valid message found
            if messages:
                LATEST_TS = messages[-1]["ts"]

    except SlackApiError as e:
        print(f"Error fetching messages: {e.response['error']}")
        if e.response['error'] == 'not_in_channel':
            print(f"Agent is not in channel {SLACK_CHANNEL_ID}. Use /invite @{AGENT_NAME} in Slack.")
    return None


def send_message(text):
    while True:
        try:
            slack_client.chat_postMessage(channel=SLACK_CHANNEL_ID, text=text)
            break
        except SlackApiError as e:
            if e.response.status_code == 429:
                retry_after = int(e.response.headers.get("Retry-After", 1))
                print(f"Rate limited. Retrying in {retry_after} seconds...")
                time.sleep(retry_after)
                continue
            else:
                print(f"Error sending message: {e.response['error']}")
                break


def generate_response(prompt):
    try:
        # Headers as per OpenRouter documentation
        headers = {
            "Authorization": f"Bearer {OPENROUTER_API_KEY}",
            "Content-Type": "application/json"
        }

        # Build messages array with system prompt and conversation history
        messages = [{"role": "system", "content": AGENT_LLM_SYSTEM_PROMPT}]

        # Add conversation history
        for msg in conversation_history[-AGENT_MAX_HISTORY:]:
            messages.append(msg)

        # Add current user message
        messages.append({"role": "user", "content": prompt})

        # Request body following OpenRouter schema
        data = {
            "model": AGENT_LLM,
            "messages": messages,
            "temperature": AGENT_LLM_TEMPERATURE,
            "max_tokens": AGENT_LLM_MAX_TOKENS,
        }

        response = requests.post(OPENROUTER_API_URL, headers=headers, json=data)
        response.raise_for_status()  # Raise an error for bad status codes

        result = response.json()

        # Extract the response content
        if "choices" in result and len(result["choices"]) > 0:
            return result["choices"][0]["message"]["content"]
        else:
            print(f"Unexpected response structure: {result}")
            return "Sorry, received an unexpected response format."

    except requests.exceptions.HTTPError as e:
        print(f"HTTP Error from OpenRouter: {e}")
        if e.response is not None:
            print(f"Response content: {e.response.text}")
            try:
                error_data = e.response.json()
                if "error" in error_data:
                    error_msg = error_data["error"].get("message", "Unknown error")
                    print(f"Error message: {error_msg}")
            except:
                pass
        return "Sorry, there was an error generating a response."
    except requests.exceptions.RequestException as e:
        print(f"Request Error: {e}")
        return "Sorry, there was a network error."
    except Exception as e:
        print(f"Unexpected error: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return "Sorry, an unexpected error occurred."


def run_agent():
    """Main function to run the Slack agent"""
    global AGENT_USER_ID

    print(f"{AGENT_NAME} is starting...")
    print(f"Using OpenRouter API with model: {AGENT_LLM}")

    # Test Slack connection on startup and get agent user ID
    try:
        auth_response = slack_client.auth_test()
        AGENT_USER_ID = auth_response.get('user_id')
        print(f"âœ“ Slack auth successful! Agent User ID: {AGENT_USER_ID}")
    except SlackApiError as e:
        print(f"âœ— Slack auth failed: {e.response['error']}")
        print("Please check your agent token")
        print("Agent cannot continue without valid Slack authentication")
        return

    # Main loop
    print(f"{AGENT_NAME} is ready! Waiting for messages from users (ignoring agent messages)...")

    while True:
        message = get_latest_message()
        if message:
            print(f"Received from user: {message}")

            # Generate response (now with context)
            reply = generate_response(message)
            print(f"Agent responding: {reply[:100]}...")  # Show first 100 chars

            # Add both user message and bot response to conversation history
            conversation_history.append({"role": "user", "content": message})
            conversation_history.append({"role": "assistant", "content": reply})

            # Keep conversation history size manageable
            if len(conversation_history) > AGENT_MAX_HISTORY * 2:
                conversation_history[:] = conversation_history[-AGENT_MAX_HISTORY:]

            send_message(reply)

        time.sleep(AGENT_POLLING_INTERVAL)  # Use configurable polling interval


if __name__ == "__main__":
    run_agent()

"""# If you're hitting slack rate limits

See the "If youâ€™re getting rate limited in slack - switch to using socket mode" section in the instructions to enable sockets and events
"""

import time
import requests
from slack_sdk import WebClient
from slack_sdk.socket_mode import SocketModeClient
from slack_sdk.socket_mode.response import SocketModeResponse
from slack_sdk.socket_mode.request import SocketModeRequest
from datetime import datetime

# Agent Configuration
AGENT_NAME = "Slack AI Agent"
AGENT_LLM = "openai/gpt-4"
AGENT_LLM_SYSTEM_PROMPT = "You are a helpful assistant agent in a Slack channel."
AGENT_LLM_TEMPERATURE = 1.0
AGENT_LLM_MAX_TOKENS = 1000
AGENT_MAX_HISTORY = 10  # Keep last 10 messages for context

# Slack Configuration
SLACK_BOT_TOKEN = "xoxb-9289779940197-9291934200246-TXt8f0bWAT8ZrcnOVzKGjelb"
SLACK_APP_TOKEN = "xapp-1-A09949YQKU1-9292075500406-35a135d487d157545748ad2a5bcf34119d5f2de699a3eb6c5afcaffb31c870e8"
# CHANNEL_ID = "C098KSPAD0E"
CHANNEL_ID = "C099ACK4P6U"

# OpenRouter Configuration
OPENROUTER_API_KEY = "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"
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"

# Initialize clients
web_client = WebClient(token=SLACK_BOT_TOKEN)

# Get bot user ID first
try:
    bot_info = web_client.auth_test()
    BOT_USER_ID = bot_info["user_id"]
    print(f"âœ“ Connected to Slack! Bot User ID: {BOT_USER_ID}")
except Exception as e:
    print(f"Failed to connect with bot token: {e}")
    exit(1)

# Initialize socket client after confirming bot token works
socket_client = SocketModeClient(
    app_token=SLACK_APP_TOKEN,
    web_client=web_client
)


# Store recent conversation history
conversation_history = []

# Track processed messages to avoid duplicates
processed_messages = set()
MESSAGE_DEDUP_WINDOW = 10  # seconds

def generate_response(prompt, history=None):
    """Generate response using OpenRouter API with optional history"""
    try:
        headers = {
            "Authorization": f"Bearer {OPENROUTER_API_KEY}",
            "Content-Type": "application/json"
        }

        messages = [{"role": "system", "content": AGENT_LLM_SYSTEM_PROMPT}]

        # Add conversation history if provided
        if history:
            for h in history[-8:]:  # Last 8 messages for context
                messages.append({"role": h["role"], "content": h["content"]})

        messages.append({"role": "user", "content": prompt})

        data = {
            "model": AGENT_LLM,
            "messages": messages,
            "temperature": AGENT_LLM_TEMPERATURE,
            "max_tokens": AGENT_LLM_MAX_TOKENS,
        }

        response = requests.post(OPENROUTER_API_URL, headers=headers, json=data)
        response.raise_for_status()

        result = response.json()

        if "choices" in result and len(result["choices"]) > 0:
            return result["choices"][0]["message"]["content"]
        else:
            return "Sorry, I couldn't generate a response."

    except Exception as e:
        print(f"Error generating response: {e}")
        return "Sorry, there was an error generating a response."


def send_message(channel, text):
    """Send a message to Slack"""
    try:
        response = web_client.chat_postMessage(
            channel=channel,
            text=text
        )
        return response
    except Exception as e:
        print(f"Error sending message: {e}")
        return None


def process_event(client: SocketModeClient, req: SocketModeRequest):
    """Process incoming events"""
    if req.type == "events_api":
        # Acknowledge the request
        response = SocketModeResponse(envelope_id=req.envelope_id)
        client.send_socket_mode_response(response)

        # Get the event
        event = req.payload.get("event", {})
        event_type = event.get("type")

        # Handle message events
        if event_type == "message":
            # Skip bot messages
            if event.get("bot_id") or event.get("user") == BOT_USER_ID:
                return

            # Skip subtypes (edits, deletes)
            if event.get("subtype"):
                return

            # Only respond in our channel
            if event.get("channel") != CHANNEL_ID:
                return

            text = event.get("text", "")
            user = event.get("user", "Unknown")
            ts = event.get("ts", "")

            # Create a unique message identifier
            message_id = f"{user}-{text}-{int(float(ts))}"

            # Skip if we've seen this message recently
            if message_id in processed_messages:
                return

            # Add to processed messages
            processed_messages.add(message_id)

            print(f"\n[{datetime.now().strftime('%H:%M:%S')}] New message from {user}: {text}")

            # Add user message to history
            conversation_history.append({"role": "user", "content": text})

            # Generate and send response with history
            reply = generate_response(text, conversation_history)
            print(f"Responding: {reply[:100]}...")

            # Add bot response to history
            conversation_history.append({"role": "assistant", "content": reply})

            # Keep history size manageable
            if len(conversation_history) > AGENT_MAX_HISTORY * 2:
                conversation_history[:] = conversation_history[-AGENT_MAX_HISTORY:]

            send_message(CHANNEL_ID, reply)
    else:
        # Acknowledge other request types
        response = SocketModeResponse(envelope_id=req.envelope_id)
        client.send_socket_mode_response(response)


def main():
    print(f"{AGENT_NAME} is starting...")
    print(f"Using OpenRouter API with model: {AGENT_LLM}")
    print(f"Monitoring channel: {CHANNEL_ID}")

    # Set up event listener
    socket_client.socket_mode_request_listeners.append(process_event)

    # Connect with better error handling
    try:
        print("Connecting to Socket Mode...")
        socket_client.connect()
        print("âœ“ Socket Mode connected!")
    except Exception as e:
        print(f"Failed to connect to Socket Mode: {e}")
        print("\nTroubleshooting:")
        print("1. Make sure Socket Mode is enabled in your app settings")
        print("2. Make sure Event Subscriptions are enabled")
        print("3. Try regenerating the Socket Mode token")
        return

    print(f"\n{AGENT_NAME} is ready!")
    print("Real-time message processing enabled - NO DELAYS!")
    print("Press Ctrl+C to stop\n")

    try:
        # Keep running
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("\nShutting down...")
        socket_client.close()


if __name__ == "__main__":
    main()

